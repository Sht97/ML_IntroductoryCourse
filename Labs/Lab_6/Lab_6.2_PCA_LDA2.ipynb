{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 6 Parte 2\n",
    "\n",
    "### Reducción de dimensión: PCA y LDA\n",
    "\n",
    "### 2019-II\n",
    "\n",
    "#### Profesor: Julián D. Arias Londoño\n",
    "#### julian.ariasl@udea.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudiantes\n",
    "\n",
    "#### Primer Integrante: Jairo David Campaña Rosero\n",
    "#### Segundo Integrante: Alejandro Mesa Gómez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En esta archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicaciones\n",
    "\n",
    "Este ejercicio tiene como objetivo implementar varias técnicas de extracción de características (PCA y LDA) y usar SVM para resolver un problema de clasificación multietiqueta o multiclase.\n",
    "\n",
    "\n",
    "Antes de iniciar a ejecutar las celdas, debe instalar la librería mlxtend que usaremos para los laboratorios de reducción de dimensión.\n",
    "Para hacerlo solo tiene que usar el siguiente comando: \n",
    "`!pip install mlxtend`\n",
    "También puede consultar la guía oficial de instalación\n",
    "    de esta librería: https://rasbt.github.io/mlxtend/installation/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\jairo\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from mlxtend) (0.21.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from mlxtend) (0.25.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from mlxtend) (3.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from mlxtend) (41.4.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from mlxtend) (1.16.5)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from mlxtend) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from mlxtend) (0.13.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->mlxtend) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from mlxtend.preprocessing import standardize\n",
    "from mlxtend.feature_extraction import PrincipalComponentAnalysis as PCA\n",
    "from mlxtend.feature_extraction import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para el problema de clasificación usaremos la siguiente base de datos: https://archive.ics.uci.edu/ml/datasets/Cardiotocography\n",
    "\n",
    "\n",
    "\n",
    "Analice la base de datos, sus características, su variable de salida y el contexto del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Analice y comprenda la siguiente celda de código donde se importan las librerías a usar y se carga la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la base de datos de entrenamiento. dim de X: (2126, 22)\tdim de Y: (2126,)\n"
     ]
    }
   ],
   "source": [
    "#cargamos la bd de entrenamiento\n",
    "db = np.loadtxt('DB/DB_Fetal_Cardiotocograms.txt',delimiter='\\t')  # Assuming tab-delimiter\n",
    "\n",
    "X = db[:,0:22]\n",
    "\n",
    "#Solo para dar formato a algunas variables\n",
    "for i in range(1,7):\n",
    "    X[:,i] = X[:,i]*1000\n",
    "\n",
    "X = X\n",
    "Y = db[:,22]\n",
    "\n",
    "#Para darle formato de entero a la variable de salida\n",
    "\n",
    "Y_l = []\n",
    "for i in Y:\n",
    "    Y_l.append(int(i))\n",
    "Y = np.asarray(Y_l)\n",
    "\n",
    "print (\"Dimensiones de la base de datos de entrenamiento. dim de X: \" + str(np.shape(X)) + \"\\tdim de Y: \" + str(np.shape(Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Entrenamiento sin extracción de características\n",
    "\n",
    "En la siguiente celda de código no tiene que completar nada. Analice, comprenda y ejecute el código y tenga en cuenta los resultados para completar la tabla que se le pide más abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error de validación sin aplicar extracción: 0.07712817787226504 +/- 0.05442325724156325\n",
      "\n",
      "Eficiencia en validación sin aplicar extracción: 92.2871822127735%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.586920976638794 segundos.\n"
     ]
    }
   ],
   "source": [
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)\n",
    "\n",
    "#Para calcular el costo computacional\n",
    "tiempo_i = time.time()\n",
    "\n",
    "#Creamos el clasificador SVM. Tenga en cuenta que el problema es multiclase. \n",
    "clf = svm.SVC(decision_function_shape='ovr', kernel='rbf', C = 100, gamma=0.0001)\n",
    "\n",
    "#Implemetamos la metodología de validación\n",
    "\n",
    "Errores = np.ones(10)\n",
    "j = 0\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "    #Aquí se entran y se valida el modelo sin hacer selección de características\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # Entrenamiento el modelo.\n",
    "    model = clf.fit(X_train,y_train)\n",
    "\n",
    "    # Validación del modelo\n",
    "    ypred = model.predict(X_test)\n",
    "    \n",
    "    #######\n",
    "\n",
    "    Errores[j] = classification_error(ypred, y_test)\n",
    "    j+=1\n",
    "\n",
    "print(\"\\nError de validación sin aplicar extracción: \" + str(np.mean(Errores)) + \" +/- \" + str(np.std(Errores)))\n",
    "print(\"\\nEficiencia en validación sin aplicar extracción: \" + str((1-np.mean(Errores))*100) + \"%\" )\n",
    "print (\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i) + \" segundos.\")\n",
    "\n",
    "#print str(ypred)\n",
    "#print str(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1.1 Cuando se aplica PCA ¿es necesario estandarizar los datos? Si, No y por qué? En qué consiste dicha estandarización?\n",
    "\n",
    "R/: Es necesario estandarizar datos en el caso de que estos se encuentren en diferente escala(diferentes desviaciones estandar). Esto es debido a que PCA es un problema de maximizacion de varianza, el cual calcula un nuevo eje basado en la desviacion estandar de las variables, una variable con mayor desviacion estandar aportara mucho más  en dicho calculo del eje que una con menor, por lo tanto, es necesario estandarizarlas para llevars a tener la misma desviacion estandar y aportar de igual manera al calculo del nuevo eje.\n",
    "    \n",
    "1.2 La proyección de los datos que realiza PCA busca optimizar un medida, ¿Cuál? Explique.\n",
    "\n",
    "R/: PCA tiene el objetivo principalmente de maximizar la varianza total de tal forma que se minimice la distancia entre los datos reales y proyecciones de estos sobre el nuevo eje generado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Entrenamiento con extracción de características\n",
    "\n",
    "En la siguiente celda, complete el código donde le sea indicado. Consulte la documentación oficial de la librería mlxtend para los métodos de extracción de características. https://rasbt.github.io/mlxtend/user_guide/feature_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature Extraction Function\n",
    "#Recibe 2 parámetros: \n",
    "1. el tipo de método de extracción (pca o lda como string),\n",
    "2. el número componentes (para pca) o el número de discriminantes (para lda)\n",
    "\n",
    "#Para este laboratorio solo se le pedirá trabajar con PCA, LDA es opcional.\n",
    "'''\n",
    "\n",
    "def extract_features(tipo, n):\n",
    "    \n",
    "    if tipo == 'pca':\n",
    "    \n",
    "        ext = PCA(n_components=n)\n",
    "    \n",
    "        return ext\n",
    "\n",
    "    elif tipo == 'lda':\n",
    "        \n",
    "        ext = LDA(n_discriminants=n)\n",
    "        \n",
    "        return ext\n",
    "    \n",
    "    else:\n",
    "        print (\"Ingrese un método válido (pca o lda)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error de validación aplicando extracción: 0.08932589246168837 +/- 0.06387058313574974\n",
      "\n",
      "Eficiencia en validación aplicando extracción: 91.06741075383115%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 3.631760358810425 segundos.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Para calcular el costo computacional\n",
    "tiempo_i = time.time()\n",
    "\n",
    "#Estandarizamos los datos\n",
    "X = standardize(X)\n",
    "\n",
    "#Implemetamos la metodología de validación cross validation con 10 folds\n",
    "\n",
    "Errores = np.ones(10)\n",
    "j = 0\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    #Aquí se aplica la extracción de características por PCA\n",
    "    #Complete el código\n",
    "    \n",
    "    ex = extract_features('pca',10)\n",
    "\n",
    "    #Fit de PCA\n",
    "    ex = ex.fit(X)\n",
    "    \n",
    "    #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "    X_ex = ex.transform(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Se aplica CV-10\n",
    "    \n",
    "    X_train, X_test = X_ex[train_index], X_ex[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]  \n",
    "   \n",
    "    #Aquí se entrena y se valida el modelo luego de aplicar extracción de características con PCA o LDA\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # Entrenamiento el modelo.\n",
    "    model = clf.fit(X_train,y_train)\n",
    "\n",
    "    # Validación del modelo\n",
    "    ypred = model.predict(X_test)\n",
    "    \n",
    "    #######\n",
    "\n",
    "    Errores[j] = classification_error(ypred, y_test)\n",
    "    j+=1\n",
    "        \n",
    "\n",
    "print(\"\\nError de validación aplicando extracción: \" + str(np.mean(Errores)) + \" +/- \" + str(np.std(Errores)))\n",
    "\n",
    "print(\"\\nEficiencia en validación aplicando extracción: \" + str((1-np.mean(Errores))*100) + \"%\" )\n",
    "\n",
    "print (\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i) + \" segundos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "3.1 En la celda de código anterior, varíe los parámetros correspondientes al número de componentes principales a tener en cuenta (use 2, 10, 19 y 21 componentes principales) para PCA y complete la siguiente tabla de resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(car, X, tipo):\n",
    "    #Para calcular el costo computacional\n",
    "    tiempo_i = time.time()\n",
    "\n",
    "    #Estandarizamos los datos\n",
    "    X = standardize(X)\n",
    "\n",
    "    #Implemetamos la metodología de validación cross validation con 10 folds\n",
    "\n",
    "    Errores = np.ones(10)\n",
    "    j = 0\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        #Aquí se aplica la extracción de características por PCA\n",
    "        #Complete el código\n",
    "\n",
    "        ex = extract_features(tipo, car)\n",
    "\n",
    "        #Fit de PCA\n",
    "        ex = ex.fit(X)\n",
    "\n",
    "        #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "        X_ex = ex.transform(X)\n",
    "\n",
    "\n",
    "        #Se aplica CV-10\n",
    "\n",
    "        X_train, X_test = X_ex[train_index], X_ex[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Aquí se entrena y se valida el modelo luego de aplicar extracción de características con PCA o LDA\n",
    "\n",
    "        ######\n",
    "\n",
    "        # Entrenamiento el modelo.\n",
    "        model = clf.fit(X_train,y_train)\n",
    "\n",
    "        # Validación del modelo\n",
    "        ypred = model.predict(X_test)\n",
    "\n",
    "        #######\n",
    "\n",
    "        Errores[j] = classification_error(ypred, y_test)\n",
    "        j+=1\n",
    "\n",
    "    return str(np.mean(Errores)), str(np.std(Errores)),str((1-np.mean(Errores))*100) + \"%\",str(time.time()-tiempo_i) + \" segundos.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8039ef54221f48d9b637a8a9d3d0f7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "df_types = pd.DataFrame({\n",
    "    'Tecnica' : pd.Series(['SVM sin extracción','SVM + PCA','SVM + PCA','SVM + PCA','SVM + PCA']),\n",
    "    '# de características seleccionadas' : pd.Series(['N/A',2,10,19,21]),\n",
    "   })\n",
    "err_val_ = []\n",
    "ic_ = []\n",
    "efic_ = []\n",
    "texec_ = []\n",
    "\n",
    "for i in zip(df_types['# de características seleccionadas']):\n",
    "    if(i[0] == 'N/A'):\n",
    "        err_val_.append(\"0.07712817787226504\")\n",
    "        ic_.append(\"0.05442325724156325\")\n",
    "        efic_.append(\"92.66365488528656%\")\n",
    "        texec_.append(\"0.4625818729400635 segundos\")\n",
    "    else:\n",
    "        err_val, ic, efic, texec = train(i[0], X, \"pca\")\n",
    "        err_val_.append(err_val)\n",
    "        ic_.append(ic)\n",
    "        efic_.append(efic)\n",
    "        texec_.append(texec)\n",
    "    \n",
    "df_types[\"Error de validación\"] = err_val_\n",
    "df_types[\"IC(std)\"] = ic_\n",
    "df_types[\"Eficiencia\"] = efic_\n",
    "df_types[\"Tiempo de ejecución\"] = texec_\n",
    "\n",
    "df_types.set_index(['Tecnica','# de características seleccionadas'], inplace=True)\n",
    "\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Error de validación</th>\n",
       "      <th>IC(std)</th>\n",
       "      <th>Eficiencia</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tecnica</th>\n",
       "      <th># de características seleccionadas</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM sin extracción</th>\n",
       "      <th>N/A</th>\n",
       "      <td>0.07712817787226504</td>\n",
       "      <td>0.05442325724156325</td>\n",
       "      <td>92.66365488528656%</td>\n",
       "      <td>0.4625818729400635 segundos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">SVM + PCA</th>\n",
       "      <th>2</th>\n",
       "      <td>0.21483745238727964</td>\n",
       "      <td>0.1709424253642628</td>\n",
       "      <td>78.51625476127204%</td>\n",
       "      <td>3.6112253665924072 segundos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.08932589246168837</td>\n",
       "      <td>0.06387058313574974</td>\n",
       "      <td>91.06741075383115%</td>\n",
       "      <td>3.141091823577881 segundos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.07383514926034193</td>\n",
       "      <td>0.04357915071494415</td>\n",
       "      <td>92.6164850739658%</td>\n",
       "      <td>3.299067735671997 segundos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.07336345114713438</td>\n",
       "      <td>0.043533331744924374</td>\n",
       "      <td>92.66365488528656%</td>\n",
       "      <td>3.3839051723480225 segundos.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Error de validación  \\\n",
       "Tecnica            # de características seleccionadas                        \n",
       "SVM sin extracción N/A                                 0.07712817787226504   \n",
       "SVM + PCA          2                                   0.21483745238727964   \n",
       "                   10                                  0.08932589246168837   \n",
       "                   19                                  0.07383514926034193   \n",
       "                   21                                  0.07336345114713438   \n",
       "\n",
       "                                                                    IC(std)  \\\n",
       "Tecnica            # de características seleccionadas                         \n",
       "SVM sin extracción N/A                                  0.05442325724156325   \n",
       "SVM + PCA          2                                     0.1709424253642628   \n",
       "                   10                                   0.06387058313574974   \n",
       "                   19                                   0.04357915071494415   \n",
       "                   21                                  0.043533331744924374   \n",
       "\n",
       "                                                               Eficiencia  \\\n",
       "Tecnica            # de características seleccionadas                       \n",
       "SVM sin extracción N/A                                 92.66365488528656%   \n",
       "SVM + PCA          2                                   78.51625476127204%   \n",
       "                   10                                  91.06741075383115%   \n",
       "                   19                                   92.6164850739658%   \n",
       "                   21                                  92.66365488528656%   \n",
       "\n",
       "                                                                Tiempo de ejecución  \n",
       "Tecnica            # de características seleccionadas                                \n",
       "SVM sin extracción N/A                                  0.4625818729400635 segundos  \n",
       "SVM + PCA          2                                   3.6112253665924072 segundos.  \n",
       "                   10                                   3.141091823577881 segundos.  \n",
       "                   19                                   3.299067735671997 segundos.  \n",
       "                   21                                  3.3839051723480225 segundos.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Analizando los resultados del punto anterior que puede decir de la viabilidad de aplicar PCA para hacer reducción de dimensión en este problema?\n",
    "\n",
    "R/: No es apropiado, ya que tanto el error como la eficiencia fueron mejores en la maquina de soporte sin extracción de características salvo en 21 características, donde el error es ligeramente menor pero a un nivel despreciable. Además, conforme se elige un numero menor de características el error aumenta, lo cual es una clara señal de que PCA no es util en este caso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Explique en sus palabras la principal ventaja que tiene LDA sobre PCA para resolver problemas de clasificación.\n",
    "\n",
    "R/: \n",
    "\n",
    "En el caso de clasificación, PCA, en su proceso de selección puede terminar traslapando clases al proyectar los datos a una dimensión menor, haciendo así que el problema aumente en complejidad. LDA busca los subespacios de características que maximicen la separación de clases, maxizando a su vez también la varianza intra clase, mientras que PCA busca la dirección de los vectores que maximice la varianza de los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Explique en sus palabras las diferencias que existen entre los métodos de selección de características y los métodos de extracción de características vistos en el curso.\n",
    "\n",
    "R/: Los metodos de extracción generan nuevas características para describir el comportamiento de los datos originales, mientras que los metodos de selección son tecnicas heurísticas que evaluan el desempeño del modelo debido a cada característica, por este motivo, es un proceso generalmente mucho más lento que extracción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Ejercicio 4: LDA (Punto opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto hará uso del método <font color='blue'>extract_features</font>  que recibe como parámetro el tipo de extracción si es PCA o LDA y el número de discriminantes, una vez se haga la transformación de las carácteristicas, se continua con el procedimiento del modelo a entrenar, en este caso es SVM. Esta es documentación para LDA [link ](https://rasbt.github.io/mlxtend/user_guide/feature_extraction/LinearDiscriminantAnalysis/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X).any())\n",
    "print(np.isnan(Y).any())\n",
    "\n",
    "print(np.isinf(X).any())\n",
    "print(np.isinf(Y).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import iris_data\n",
    "X, y = iris_data()\n",
    "X = standardize(X)\n",
    "\n",
    "lda = LDA(n_discriminants=2)\n",
    "lda.fit(X, y)\n",
    "X_lda = lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.reshape(Y, (Y.shape[0],1))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lda(car, tipo, X, Y):\n",
    "    #Para calcular el costo computacional\n",
    "    tiempo_i = time.time()\n",
    "\n",
    "    #Estandarizamos los datos\n",
    "    X = standardize(X)\n",
    "        #Aquí se aplica la extracción de características por PCA\n",
    "    #Complete el código\n",
    "\n",
    "    ex = LDA(n_discriminants = car)\n",
    "\n",
    "    #Fit de PCA\n",
    "    ex = ex.fit(X,Y)\n",
    "\n",
    "    #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "    X_ex = ex.transform(X)\n",
    "\n",
    "\n",
    "    #Implemetamos la metodología de validación cross validation con 10 folds\n",
    "\n",
    "    Errores = np.ones(10)\n",
    "    j = 0\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "\n",
    "\n",
    "        #Se aplica CV-10\n",
    "\n",
    "        X_train, X_test = X_ex[train_index], X_ex[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Aquí se entrena y se valida el modelo luego de aplicar extracción de características con PCA o LDA\n",
    "\n",
    "        ######\n",
    "\n",
    "        # Entrenamiento el modelo.\n",
    "        model = clf.fit(X_train,y_train)\n",
    "\n",
    "        # Validación del modelo\n",
    "        ypred = model.predict(X_test)\n",
    "\n",
    "        #######\n",
    "\n",
    "        Errores[j] = classification_error(ypred, y_test)\n",
    "        j+=1\n",
    "\n",
    "    return str(np.mean(Errores)), str(np.std(Errores)),str((1-np.mean(Errores))*100) + \"%\",str(time.time()-tiempo_i) + \" segundos.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-1fa39cf11594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-07ad03e3243e>\u001b[0m in \u001b[0;36mtrain_lda\u001b[0;34m(car, tipo, X, Y)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Fit de PCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#Transforme las variables y genere el nuevo espacio de características de menor dimensión\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mlxtend/feature_extraction/linear_discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, n_classes)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mlxtend/feature_extraction/linear_discriminant_analysis.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, n_classes)\u001b[0m\n\u001b[1;32m     89\u001b[0m                                                 mean_vectors=mean_vecs)\n\u001b[1;32m     90\u001b[0m         self.e_vals_, self.e_vecs_ = self._eigendecom(\n\u001b[0;32m---> 91\u001b[0;31m             within_scatter=within_scatter, between_scatter=between_scatter)\n\u001b[0m\u001b[1;32m     92\u001b[0m         self.w_ = self._projection_matrix(eig_vals=self.e_vals_,\n\u001b[1;32m     93\u001b[0m                                           \u001b[0meig_vecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_vecs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mlxtend/feature_extraction/linear_discriminant_analysis.py\u001b[0m in \u001b[0;36m_eigendecom\u001b[0;34m(self, within_scatter, between_scatter)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_eigendecom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithin_scatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetween_scatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         e_vals, e_vecs = np.linalg.eig(np.linalg.inv(within_scatter).dot(\n\u001b[0;32m--> 146\u001b[0;31m             between_scatter))\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0msort_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0me_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36meig\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0m_assertNdSquareness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m     \u001b[0m_assertFinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_assertFinite\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Array must not contain infs or NaNs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_isEmpty2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "train_lda(10,\"\",X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA2\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "def train_lda2(car, tipo, X, Y):\n",
    "    #Para calcular el costo computacional\n",
    "    tiempo_i = time.time()\n",
    "\n",
    "    #Estandarizamos los datos\n",
    "    X = scale(X)\n",
    "\n",
    "    #Implemetamos la metodología de validación cross validation con 10 folds\n",
    "\n",
    "    Errores = np.ones(10)\n",
    "    j = 0\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        #Aquí se aplica la extracción de características por PCA\n",
    "        #Complete el código\n",
    "\n",
    "        ex = LDA2(n_components=10)\n",
    "        #Fit de PCA\n",
    "        ex = ex.fit(X,Y)\n",
    "\n",
    "        #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "        X_ex = ex.transform(X)\n",
    "\n",
    "\n",
    "        #Se aplica CV-10\n",
    "\n",
    "        X_train, X_test = X_ex[train_index], X_ex[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Aquí se entrena y se valida el modelo luego de aplicar extracción de características con PCA o LDA\n",
    "\n",
    "        ######\n",
    "\n",
    "        # Entrenamiento el modelo.\n",
    "        model = clf.fit(X_train,y_train)\n",
    "\n",
    "        # Validación del modelo\n",
    "        ypred = model.predict(X_test)\n",
    "\n",
    "        #######\n",
    "\n",
    "        Errores[j] = classification_error(ypred, y_test)\n",
    "        j+=1\n",
    "\n",
    "    return str(np.mean(Errores)), str(np.std(Errores)),str((1-np.mean(Errores))*100) + \"%\",str(time.time()-tiempo_i) + \" segundos.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.07474754185490302',\n",
       " '0.05435890079129884',\n",
       " '92.52524581450969%',\n",
       " '0.3339509963989258 segundos.')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lda2(2, \"lda\", X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1b7fc1260b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtexec_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.4625818729400635 segundos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0merr_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mefic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0merr_val_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mic_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-220d0055a0bf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(car, X, tipo)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#Fit de PCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#Transforme las variables y genere el nuevo espacio de características de menor dimensión\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "df_types = pd.DataFrame({\n",
    "    'Tecnica' : pd.Series(['SVM sin extracción','SVM + LDA','SVM + LDA','SVM + LDA','SVM + LDA']),\n",
    "    '# de discriminantes' : pd.Series(['N/A',2,10,19,21]),   })\n",
    "\n",
    "err_val_ = []\n",
    "ic_ = []\n",
    "efic_ = []\n",
    "texec_ = []\n",
    "\n",
    "for i in zip(df_types['# de discriminantes']):\n",
    "    if(i[0] == 'N/A'):\n",
    "        err_val_.append(\"0.07712817787226504\")\n",
    "        ic_.append(\"0.05442325724156325\")\n",
    "        efic_.append(\"92.66365488528656%\")\n",
    "        texec_.append(\"0.4625818729400635 segundos\")\n",
    "    else:\n",
    "        err_val, ic, efic, texec = train_lda(i[0], \"lda\")\n",
    "        err_val_.append(err_val)\n",
    "        ic_.append(ic)\n",
    "        efic_.append(efic)\n",
    "        texec_.append(texec)\n",
    "    \n",
    "df_types[\"Error de validación\"] = err_val_\n",
    "df_types[\"IC(std)\"] = ic_\n",
    "df_types[\"Eficiencia\"] = efic_\n",
    "df_types[\"Tiempo de ejecución\"] = texec_\n",
    "\n",
    "    \n",
    "df_types[\"Error de validación\"] = err_val_\n",
    "df_types[\"IC(std)\"] = ic_\n",
    "df_types[\"Eficiencia\"] = efic_\n",
    "df_types[\"Tiempo de ejecución\"] = texec_\n",
    "\n",
    "\n",
    "df_types.set_index(['Tecnica','# de discriminantes'], inplace=True)\n",
    "\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget2 = qgrid.show_grid(df_types, show_toolbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Error de validación</th>\n",
       "      <th>IC(std)</th>\n",
       "      <th>Eficiencia</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tecnica</th>\n",
       "      <th># de discriminantes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM sin extracción</th>\n",
       "      <th>N/A</th>\n",
       "      <td>0.07712817787226504</td>\n",
       "      <td>0.05442325724156325</td>\n",
       "      <td>92.66365488528656%</td>\n",
       "      <td>0.4625818729400635 segundos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">SVM + LDA</th>\n",
       "      <th>2</th>\n",
       "      <td>0.21483745238727964</td>\n",
       "      <td>0.1709424253642628</td>\n",
       "      <td>78.51625476127204%</td>\n",
       "      <td>3.3058104515075684 segundos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.08932589246168837</td>\n",
       "      <td>0.06387058313574974</td>\n",
       "      <td>91.06741075383115%</td>\n",
       "      <td>3.1073663234710693 segundos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.07383514926034193</td>\n",
       "      <td>0.04357915071494415</td>\n",
       "      <td>92.6164850739658%</td>\n",
       "      <td>3.0319924354553223 segundos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.07336345114713438</td>\n",
       "      <td>0.043533331744924374</td>\n",
       "      <td>92.66365488528656%</td>\n",
       "      <td>2.9479408264160156 segundos.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Error de validación  \\\n",
       "Tecnica            # de discriminantes                        \n",
       "SVM sin extracción N/A                  0.07712817787226504   \n",
       "SVM + LDA          2                    0.21483745238727964   \n",
       "                   10                   0.08932589246168837   \n",
       "                   19                   0.07383514926034193   \n",
       "                   21                   0.07336345114713438   \n",
       "\n",
       "                                                     IC(std)  \\\n",
       "Tecnica            # de discriminantes                         \n",
       "SVM sin extracción N/A                   0.05442325724156325   \n",
       "SVM + LDA          2                      0.1709424253642628   \n",
       "                   10                    0.06387058313574974   \n",
       "                   19                    0.04357915071494415   \n",
       "                   21                   0.043533331744924374   \n",
       "\n",
       "                                                Eficiencia  \\\n",
       "Tecnica            # de discriminantes                       \n",
       "SVM sin extracción N/A                  92.66365488528656%   \n",
       "SVM + LDA          2                    78.51625476127204%   \n",
       "                   10                   91.06741075383115%   \n",
       "                   19                    92.6164850739658%   \n",
       "                   21                   92.66365488528656%   \n",
       "\n",
       "                                                 Tiempo de ejecución  \n",
       "Tecnica            # de discriminantes                                \n",
       "SVM sin extracción N/A                   0.4625818729400635 segundos  \n",
       "SVM + LDA          2                    3.3058104515075684 segundos.  \n",
       "                   10                   3.1073663234710693 segundos.  \n",
       "                   19                   3.0319924354553223 segundos.  \n",
       "                   21                   2.9479408264160156 segundos.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget2.get_changed_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
